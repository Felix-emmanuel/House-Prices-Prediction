This project is aimed at analyzing data with feedforward neural network and experiment systematically with different hyperparameter configurations, e.g. the learning rate, batch size, number of hidden units, layers, etc.
Over the past few years there has been rising waves of interests in Neural Networks and their applications. More of the modern algorithms that are now being deployed are built based on the existing foundation created in the 80s and up to the 90s. Some of these work are centered around using techniques to create performance optimization for the networks without sacrificing the quality or standard of the algorithm to predict on untested dataset. The techniques can be used to focus on a certain aspect of the network or apply globally to an array of network 

